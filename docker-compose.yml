version: '3.7'
services:
  db:
    image: postgres:12
    env_file:
      - dev-environment/db.env
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./docker/postgres-initdb.d/10-test-for-valid-env-variables.sh:/docker-entrypoint-initdb.d/10-test-for-valid-env-variables.sh
      - ./docker/postgres-initdb.d/20-create-admin-db-and-user.sh:/docker-entrypoint-initdb.d/20-create-admin-db-and-user.sh
      - ./docker/postgres-initdb.d/40-create-report-db-and-user.sh:/docker-entrypoint-initdb.d/40-create-report-db-and-user.sh
      # The following file adds the CREATEDB privilege to the db users to enable it
      # to run the django tests.
      # THIS SHOULD NOT BE USED IN PRODUCTION!!!
      - ./dev-environment/postgres-initdb.d/50-add-createdb-permissions.sh:/docker-entrypoint-initdb.d/50-add-createdb-permissions.sh

  queue:
    # Normally, we expect the `rabbitmq` image. The -management images come
    # with a set of management plugins installed and enabled by default.
    # They can be accessed through the web interface on port 15672 (or the port
    # it has been remapped to).
    # The credentials are given in the specified `rabbitmq.env` file.
    image: rabbitmq:3-management-alpine
    hostname: os2datascanner_msg_broker
    env_file:
      - dev-environment/rabbitmq.env
    ports:
      - "5672:5672"
      - "8030:15672"

  admin_frontend:
    build:
      context: .
      dockerfile: docker/admin/Dockerfile
      target: frontend
    volumes:
      - ./src/os2datascanner/projects/admin/adminapp/static/src:/code/src/os2datascanner/projects/admin/adminapp/static/src
      - frontend-bundles-admin:/code/src/os2datascanner/projects/admin/adminapp/static/dist/
      - /code/frontend/mode_modules

  report_frontend:
     build:
       context: .
       dockerfile: docker/report/Dockerfile
       target: frontend
     volumes:
       - ./src/os2datascanner/projects/report/reportapp/static/src:/code/src/os2datascanner/projects/report/reportapp/static/src
       - frontend-bundles-report:/code/src/os2datascanner/projects/report/reportapp/static/dist/
       - /code/frontend/mode_modules

  admin_application:
    build:
      context: .
      dockerfile: docker/admin/Dockerfile
      target: application
    command: [
      "gunicorn",
      "--config", "/code/docker/gunicorn-settings.py",
      "--reload", # restart workers when code changes
      "wsgi"
    ]
    environment:
      - GUNICORN_WORKERS=2
    volumes:
      - frontend-bundles-admin:/code/src/os2datascanner/projects/admin/adminapp/static/dist/
      - ./dev-environment/admin/dev-settings.toml:/user-settings.toml
      - ./dev-environment/admin/.secret:/code/.secret
      - ./src/os2datascanner:/code/src/os2datascanner
    ports:
      - "8020:5000"
    depends_on:
      - db
      - admin_frontend
      - queue

  admin_collector:
    build:
      context: .
      dockerfile: docker/admin/Dockerfile
      target: application
    environment:
      - OS2DS_SKIP_DJANGO_MIGRATIONS=1
    command: python manage.py pipeline_collector
    volumes:
      - ./dev-environment/admin/dev-settings.toml:/user-settings.toml
      - ./src/os2datascanner:/code/src/os2datascanner
    depends_on:
      - db
      - admin_application
      - queue

  report_application:
    build:
      context: .
      dockerfile: docker/report/Dockerfile
      target: application
    command: [
      "gunicorn",
      "--config", "/code/docker/gunicorn-settings.py",
      "--reload", # restart workers when code changes
      "wsgi"
    ]
    environment:
      - GUNICORN_WORKERS=2
    volumes:
      - frontend-bundles-report:/code/src/os2datascanner/projects/report/reportapp/static/dist/
      - ./dev-environment/report/dev-settings.toml:/user-settings.toml
      - ./src/os2datascanner:/code/src/os2datascanner
    ports:
      - "8040:5000"
    depends_on:
      - db
      - report_frontend
      - queue

  report_collector:
    build:
      context: .
      dockerfile: docker/report/Dockerfile
      target: application
    environment:
      - OS2DS_SKIP_DJANGO_MIGRATIONS=1
    command: python manage.py pipeline_collector
    volumes:
      - ./dev-environment/report/dev-settings.toml:/user-settings.toml
      - ./src/os2datascanner:/code/src/os2datascanner
    depends_on:
      - db
      - report_application
      - queue

  engine_explorer:
    build:
      context: .
      dockerfile: docker/engine/Dockerfile
      target: engine
    command: explorer --enable-metrics
    init: true
    volumes:
      - ./dev-environment/engine/dev-settings.toml:/user-settings.toml
      - ./src/os2datascanner:/code/src/os2datascanner
    depends_on:
      - queue

  engine_worker:
    build:
      context: .
      dockerfile: docker/engine/Dockerfile
      target: engine
    command: worker --enable-metrics
    init: true
    volumes:
      - ./dev-environment/engine/dev-settings.toml:/user-settings.toml
      - ./src/os2datascanner:/code/src/os2datascanner
    depends_on:
      - queue

  engine_exporter:
    build:
      context: .
      dockerfile: docker/engine/Dockerfile
      target: engine
    command: exporter --enable-metrics
    init: true
    volumes:
      - ./dev-environment/engine/dev-settings.toml:/user-settings.toml
      - ./src/os2datascanner:/code/src/os2datascanner
    depends_on:
      - queue

## Disabled until everyone has updated `docker-compose` to v1.28+
#  a11y_scanner:
#    build:
#      context: ./services/a11y-scanner
#      dockerfile: docker/Dockerfile
#    env_file:
#      - ./dev-environment/a11y-scanner/a11y-scanner.env
#    # Set only the necessary security permissions
#    security_opt:
#      - seccomp:./services/a11y-scanner/chrome_seccomp.json
#    ports:
#      - 8888:8888
#    profiles:
#      - a11y

  api_server:
    build:
      context: .
      dockerfile: docker/api/Dockerfile
      target: application
    command: [
        "gunicorn",
        "--config", "/code/docker/gunicorn-settings.py",
        "--workers", "2", # only two workers in local dev - to save some resources
        "--reload", # restart workers when code changes
        "os2datascanner.server.wsgi"
    ]
    ports:
      - "8070:5000"
    volumes:
      - ./dev-environment/api/dev-settings.toml:/user-settings.toml
      - ./src/os2datascanner:/code/src/os2datascanner

  swagger_ui:
    image: swaggerapi/swagger-ui:v3.41.1
    environment:
      - SWAGGER_JSON_URL=http://localhost:8070/openapi.yaml
    ports:
      - "8075:8080"
    depends_on:
      - api_server

  prometheus:
    image: prom/prometheus
    volumes:
      - "./dev-environment/prometheus.yml:/etc/prometheus/prometheus.yml:ro"
    ports:
      - "8050:9090"

  # default user is admin/admin
  grafana:
    image: grafana/grafana
    volumes:
      - "./dev-environment/grafana/datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml:ro"
      - "./dev-environment/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro"
    ports:
      - "8060:3000"

  idp:
    image: magentalabs/simplesamlphp:2.0.1
    environment:
      - SIMPLESAMLPHP_BASEURLPATH=http://localhost:8080/simplesaml/
      - SIMPLESAMLPHP_SP_ENTITY_ID=http://localhost:8040/saml2_auth/acs/
      - SIMPLESAMLPHP_SP_ASSERTION_CONSUMER_SERVICE=http://localhost:8040/saml2_auth/acs/
# Replace the three env variables above with these below, if you wish to test Keycloak.
#      - SIMPLESAMLPHP_SP_ENTITY_ID=http://localkeycloak.os2datascanner:8090/auth/realms/magenta
#      - SIMPLESAMLPHP_SP_ASSERTION_CONSUMER_SERVICE=http://localkeycloak.os2datascanner:8090/auth/realms/magenta/broker/saml/endpoint
#      - SIMPLESAMLPHP_SP_SINGLE_LOGOUT_SERVICE=http://localkeycloak.os2datascanner:8090/auth/realms/magenta/broker/saml/endpoint
    volumes:
      - ./dev-environment/authsources.php:/var/www/simplesamlphp/config/authsources.php
    ports:
      - "8080:8080"

  postgres-keycloak:
    image: postgres
    environment:
      POSTGRES_DB: keycloak
      POSTGRES_USER: keycloak
      POSTGRES_PASSWORD: keycloak
    volumes:
      - type: volume
        source: knr-postgres-keycloak-volume
        target: /var/lib/postgresql/data

  localkeycloak.os2datascanner:
    image: quay.io/keycloak/keycloak:12.0.0

    # Import of realm is done with migration commands below
    # because we need to predefine the Master realm.
    # Using the KEYCLOAK_IMPORT env variable or the -Dkeycloak.import flag will not
    # work, as it will create a Master realm, then try but fail to create a
    # new Master realm from our json file.

    # migration.strategy=OVERWRITE_EXISTING will drop & create if changes has occurred
    # and is set to our default setting.
    # IGNORE_EXISTING will not import if a realm of this name already exists
    # which could be useful if you need to test other Keycloak settings.
    command: [ "-Djboss.socket.binding.port-offset=10",
               "-Dkeycloak.migration.action=import",
               "-Dkeycloak.migration.provider=singleFile",
               "-Dkeycloak.migration.file=/realm.json",
               "-Dkeycloak.migration.strategy=IGNORE_EXISTING",
             ]
    ports:
      - 8090:8090
    environment:
      KEYCLOAK_USER: admin
      KEYCLOAK_PASSWORD: admin
      # PROXY_ADDRESS_FORWARDING: "true"
      DB_USER: keycloak
      DB_PASSWORD: keycloak
      DB_ADDR: postgres-keycloak
      DB_DATABASE: keycloak
      DB_SCHEMA: public
      DB_VENDOR: POSTGRES
    volumes:
      - ./dev-environment/realm.json:/realm.json
    depends_on:
      - postgres-keycloak

  ldap_server:
    image: osixia/openldap
    environment:
      LDAP_ADMIN_PASSWORD: testMAG
      LDAP_BASE_DN: dc=magenta,dc=test
      LDAP_ORGANISATION: Magenta
      LDAP_DOMAIN: magenta.test
    ports:
      - 389:389
    volumes:
      - ldap_data:/var/lib/ldap
      - ldap_config:/etc/ldap/slapd.d

  ldap_server_admin:
    image: osixia/phpldapadmin
    ports:
    - 8100:80
    environment:
      PHPLDAPADMIN_LDAP_HOSTS: ldap_server
      PHPLDAPADMIN_HTTPS: 'false'
    depends_on:
      - ldap_server

x-disabled:
  admin_cron:
    build:
      context: .
      dockerfile: docker/admin/Dockerfile
      target: application
    command: supercronic /code/docker/crontab
    environment:
      - OS2DS_SKIP_DJANGO_MIGRATIONS=1
    volumes:
      - ./dev-environment/admin/dev-settings.toml:/user-settings.toml
      - ./src/os2datascanner:/code/src/os2datascanner
    depends_on:
      - db
      - admin_application
      - queue

  report_cron:
    build:
      context: .
      dockerfile: docker/report/Dockerfile
      target: application
    command: supercronic /code/docker/crontab
    environment:
      - OS2DS_SKIP_DJANGO_MIGRATIONS=1
    volumes:
      - ./dev-environment/report/dev-settings.toml:/user-settings.toml
      - ./src/os2datascanner:/code/src/os2datascanner
    depends_on:
      - db
      - report_application
      - queue

  engine_processor:
    build:
      context: .
      dockerfile: docker/engine/Dockerfile
      target: engine
    command: processor --enable-metrics
    init: true
    volumes:
      - ./dev-environment/engine/dev-settings.toml:/user-settings.toml
      - ./src/os2datascanner:/code/src/os2datascanner
    depends_on:
      - queue

  engine_matcher:
    build:
      context: .
      dockerfile: docker/engine/Dockerfile
      target: engine
    command: matcher --enable-metrics
    init: true
    restart: unless-stopped
    volumes:
      - ./dev-environment/engine/dev-settings.toml:/user-settings.toml
      - ./src/os2datascanner:/code/src/os2datascanner
    depends_on:
      - queue

  engine_tagger:
    build:
      context: .
      dockerfile: docker/engine/Dockerfile
      target: engine
    command: tagger --enable-metrics
    init: true
    volumes:
      - ./dev-environment/engine/dev-settings.toml:/user-settings.toml
      - ./src/os2datascanner:/code/src/os2datascanner
    depends_on:
      - queue


volumes:
  frontend-bundles-admin:
  frontend-bundles-report:
  postgres-data:
  postgres-initdb.d:
  knr-postgres-keycloak-volume:
  ldap_data:
  ldap_config:
