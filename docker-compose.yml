version: '3.9'

services:
  db:
    image: postgres:12
    env_file:
      - dev-environment/db.env
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./docker/postgres-initdb.d/10-test-for-valid-env-variables.sh:/docker-entrypoint-initdb.d/10-test-for-valid-env-variables.sh
      - ./docker/postgres-initdb.d/20-create-admin-db-and-user.sh:/docker-entrypoint-initdb.d/20-create-admin-db-and-user.sh
      - ./docker/postgres-initdb.d/40-create-report-db-and-user.sh:/docker-entrypoint-initdb.d/40-create-report-db-and-user.sh
      - ./dev-environment/postgres-initdb.d/50-add-createdb-permissions.sh:/docker-entrypoint-initdb.d/50-add-createdb-permissions.sh

  queue:
    # Normally, we expect the `rabbitmq` image. The -management images come
    # with a set of management plugins installed and enabled by default. They
    # can be accessed through a web interface. The credentials are os2ds/os2ds.
    image: rabbitmq:3.8-management-alpine
    hostname: os2datascanner_msg_broker
    env_file:
      - dev-environment/rabbitmq.env
    ports:
      - "8030:15672"  # management port

  admin_frontend:
    build:
      context: .
      dockerfile: docker/admin/Dockerfile
      target: frontend
    volumes:
      - ./src/os2datascanner/frontend:/code/src/os2datascanner/frontend
      - frontend-bundles-admin:/code/src/os2datascanner/projects/admin/adminapp/static/

  report_frontend:
     build:
       context: .
       dockerfile: docker/report/Dockerfile
       target: frontend
     volumes:
       - ./src/os2datascanner/frontend:/code/src/os2datascanner/frontend
       - frontend-bundles-report:/code/src/os2datascanner/projects/report/reportapp/static/

  admin:
    build:
      context: .
      dockerfile: docker/admin/Dockerfile
    command: [
      # In production, we use gunicorn with the worker class
      # "uvicorn.workers.UvicornWorker", but that does not work with --reload,
      # so we use uvicorn in development at the cost of some dev/prod parity.
      "uvicorn",
      "--reload",
      "--host", "0.0.0.0",
      "--port", "5000",
      # reload when translations are compiled with `docker-compose exec admin django-admin compilemessages`
      "--reload-include", "*.mo",
      "os2datascanner.projects.admin.asgi:application",
    ]
    environment:
      - GUNICORN_WORKERS=2
    volumes:
      - frontend-bundles-admin:/code/src/os2datascanner/projects/admin/adminapp/static/
      - ./dev-environment/admin/dev-settings.toml:/user-settings.toml
      - ./dev-environment/admin/.secret:/code/.secret
      - ./src/os2datascanner:/code/src/os2datascanner
    ports:
      - "8020:5000"
    depends_on:
      - db
      - admin_frontend
      - queue

  admin_collector:
    build:
      context: .
      dockerfile: docker/admin/Dockerfile
    environment:
      - OS2DS_SKIP_DJANGO_MIGRATIONS=1
    command: python manage.py pipeline_collector
    volumes:
      - ./dev-environment/admin/dev-settings.toml:/user-settings.toml
      - ./src/os2datascanner:/code/src/os2datascanner
    depends_on:
      - db
      - admin
      - queue

  admin_job_runner:
    restart: unless-stopped
    build:
      context: .
      dockerfile: docker/admin/Dockerfile
    environment:
      - OS2DS_SKIP_DJANGO_MIGRATIONS=1
    command: python manage.py run_background_jobs
    volumes:
      - ./dev-environment/admin/dev-settings.toml:/user-settings.toml
      - ./src/os2datascanner:/code/src/os2datascanner
    depends_on:
      - db
      - admin
      - queue

  report:
    build:
      context: .
      dockerfile: docker/report/Dockerfile
    command: [
      # In production, we use gunicorn with the worker class
      # "uvicorn.workers.UvicornWorker", but that does not work with --reload,
      # so we use uvicorn in development at the cost of some dev/prod parity.
      "uvicorn",
      "--reload",
      "--host", "0.0.0.0",
      "--port", "5000",
      # reload when translations are compiled with `docker-compose exec report django-admin compilemessages`
      "--reload-include", "*.mo",
      "os2datascanner.projects.report.asgi:application",
    ]
    environment:
      - GUNICORN_WORKERS=2
    volumes:
      - frontend-bundles-report:/code/src/os2datascanner/projects/report/reportapp/static/
      - ./dev-environment/report/dev-settings.toml:/user-settings.toml
      - ./src/os2datascanner:/code/src/os2datascanner
    ports:
      - "8040:5000"
    depends_on:
      - db
      - report_frontend
      - queue

  redis:
    # Channel layer backend
    image: redis:latest
    profiles:
      - socket

  report_collector:
    build:
      context: .
      dockerfile: docker/report/Dockerfile
    environment:
      - OS2DS_SKIP_DJANGO_MIGRATIONS=1
    command: python manage.py pipeline_collector
    volumes:
      - ./dev-environment/report/dev-settings.toml:/user-settings.toml
      - ./src/os2datascanner:/code/src/os2datascanner
    depends_on:
      - db
      - report
      - queue

  explorer:
    build:
      context: .
      dockerfile: docker/engine/Dockerfile
    command: explorer --enable-metrics
    init: true
    volumes:
      - ./dev-environment/engine/dev-settings.toml:/user-settings.toml
      - ./src/os2datascanner:/code/src/os2datascanner
    depends_on:
      - queue

  worker:
    build:
      context: .
      dockerfile: docker/engine/Dockerfile
    command: worker --enable-metrics
    init: true
    volumes:
      - ./dev-environment/engine/dev-settings.toml:/user-settings.toml
      - ./src/os2datascanner:/code/src/os2datascanner
    depends_on:
      - queue

  exporter:
    build:
      context: .
      dockerfile: docker/engine/Dockerfile
    command: exporter --enable-metrics
    init: true
    volumes:
      - ./dev-environment/engine/dev-settings.toml:/user-settings.toml
      - ./src/os2datascanner:/code/src/os2datascanner
    depends_on:
      - queue

  docs:
    image: nicksantamaria/mkdocs
    volumes:
      - ./:/data
    command: ["serve", "-a", "0.0.0.0:8000"]
    ports:
      - 8000:8000

  # a11y is short for "accessibility". There are 11 chars between a-y
  a11y_scanner:
    build:
      context: ./services/a11y-scanner
      dockerfile: docker/Dockerfile
    env_file:
      - ./dev-environment/a11y-scanner/a11y-scanner.env
    # This is commented because you cant use docker-compose from different dirs
    # until https://github.com/docker/compose/issues/8470 is resolved.
    #
    # Set only the necessary security permissions
    # security_opt:
    #   - seccomp:./services/a11y-scanner/chrome_seccomp.json
    ports:
      - 8888:8888
    profiles:
      - a11y

  api_server:
    build:
      context: .
      dockerfile: docker/api/Dockerfile
    command: [
        "gunicorn",
        "--config", "/code/docker/gunicorn-settings.py",
        "--workers", "2", # only two workers in local dev - to save some resources
        "--reload", # restart workers when code changes
        "os2datascanner.server.wsgi"
    ]
    ports:
      - "8070:5000"
    volumes:
      - ./dev-environment/api/dev-settings.toml:/user-settings.toml
      - ./src/os2datascanner:/code/src/os2datascanner
    profiles:
      - api

  swagger_ui:
    image: swaggerapi/swagger-ui:v3.41.1
    environment:
      - SWAGGER_JSON_URL=http://localhost:8070/openapi.yaml
    ports:
      - "8075:8080"
    depends_on:
      - api_server
    profiles:
      - api

  prometheus:
    image: prom/prometheus
    volumes:
      - "./dev-environment/prometheus.yml:/etc/prometheus/prometheus.yml:ro"
    ports:
      - "8050:9090"
    profiles:
      - metric

  # default user is admin/admin
  grafana:
    image: grafana/grafana
    volumes:
      - "./dev-environment/grafana/datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml:ro"
      - "./dev-environment/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro"
    ports:
      - "8060:3000"
    profiles:
      - metric

  idp:
    image: magentalabs/simplesamlphp:2.0.1
    environment:
      - SIMPLESAMLPHP_BASEURLPATH=http://localhost:8080/simplesaml/
      - SIMPLESAMLPHP_SP_ENTITY_ID=http://localhost:8040/saml2_auth/acs/
      - SIMPLESAMLPHP_SP_ASSERTION_CONSUMER_SERVICE=http://localhost:8040/saml2_auth/acs/
# Replace the three env variables above with these below, if you wish to test Keycloak.
#      - SIMPLESAMLPHP_SP_ENTITY_ID=http://localkeycloak.os2datascanner:8090/auth/realms/magenta
#      - SIMPLESAMLPHP_SP_ASSERTION_CONSUMER_SERVICE=http://localkeycloak.os2datascanner:8090/auth/realms/magenta/broker/saml/endpoint
#      - SIMPLESAMLPHP_SP_SINGLE_LOGOUT_SERVICE=http://localkeycloak.os2datascanner:8090/auth/realms/magenta/broker/saml/endpoint
    volumes:
      - ./dev-environment/authsources.php:/var/www/simplesamlphp/config/authsources.php
    ports:
      - "8080:8080"
    profiles:
      - sso

  postgres-keycloak:
    image: postgres
    environment:
      POSTGRES_DB: keycloak
      POSTGRES_USER: keycloak
      POSTGRES_PASSWORD: keycloak
    volumes:
      - type: volume
        source: knr-postgres-keycloak-volume
        target: /var/lib/postgresql/data
    profiles:
      - ldap
      - sso

  localkeycloak.os2datascanner:
    image: quay.io/keycloak/keycloak:12.0.0

    # Import of realm is done with migration commands below
    # because we need to predefine the Master realm.
    # Using the KEYCLOAK_IMPORT env variable or the -Dkeycloak.import flag will not
    # work, as it will create a Master realm, then try but fail to create a
    # new Master realm from our json file.

    # migration.strategy=OVERWRITE_EXISTING will drop & create if changes has occurred
    # and is set to our default setting.
    # IGNORE_EXISTING will not import if a realm of this name already exists
    # which could be useful if you need to test other Keycloak settings.
    command: [ "-Djboss.socket.binding.port-offset=10",
               "-Dkeycloak.migration.action=import",
               "-Dkeycloak.migration.provider=singleFile",
               "-Dkeycloak.migration.file=/realm.json",
               "-Dkeycloak.migration.strategy=IGNORE_EXISTING",
             ]
    ports:
      - 8090:8090
    environment:
      KEYCLOAK_USER: admin
      KEYCLOAK_PASSWORD: admin
      # PROXY_ADDRESS_FORWARDING: "true"
      DB_USER: keycloak
      DB_PASSWORD: keycloak
      DB_ADDR: postgres-keycloak
      DB_DATABASE: keycloak
      DB_SCHEMA: public
      DB_VENDOR: POSTGRES
    volumes:
      - ./dev-environment/realm.json:/realm.json
    depends_on:
      - postgres-keycloak
    profiles:
      - ldap
      - sso

  ldap_server:
    image: osixia/openldap
    environment:
      LDAP_ADMIN_PASSWORD: testMAG
      LDAP_BASE_DN: dc=magenta,dc=test
      LDAP_ORGANISATION: Magenta
      LDAP_DOMAIN: magenta.test
    ports:
      - 389:389
    volumes:
      - ldap_data:/var/lib/ldap
      - ldap_config:/etc/ldap/slapd.d
    profiles:
      - ldap

  ldap_server_admin:
    image: osixia/phpldapadmin
    ports:
    - 8100:80
    environment:
      PHPLDAPADMIN_LDAP_HOSTS: ldap_server
      PHPLDAPADMIN_HTTPS: 'false'
    depends_on:
      - ldap_server
    profiles:
      - ldap

  samba:
    image: magentalabs/samba-test:1.1
    volumes:
      - ./src/os2datascanner/engine2/tests/data/engine2:/mnt
    ports:
      - 8139:139
      - 8445:445
    environment:
      SMB_USER: os2
      SMB_PASSWD: swordfish
      SMB_SHARE_NAME: e2test
      SMB_SHARE_PATH: /mnt
      SMB_SHARE_BROWSABLE: "no"
      SMB_SHARE_READONLY: "yes"
    profiles:
      - samba

x-disabled:
  admin_cron:
    build:
      context: .
      dockerfile: docker/admin/Dockerfile
    command: supercronic /code/docker/crontab
    environment:
      - OS2DS_SKIP_DJANGO_MIGRATIONS=1
    volumes:
      - ./dev-environment/admin/dev-settings.toml:/user-settings.toml
      - ./src/os2datascanner:/code/src/os2datascanner
    depends_on:
      - db
      - admin
      - queue

  report_cron:
    build:
      context: .
      dockerfile: docker/report/Dockerfile
    command: supercronic /code/docker/crontab
    environment:
      - OS2DS_SKIP_DJANGO_MIGRATIONS=1
    volumes:
      - ./dev-environment/report/dev-settings.toml:/user-settings.toml
      - ./src/os2datascanner:/code/src/os2datascanner
    depends_on:
      - db
      - report
      - queue

  processor:
    build:
      context: .
      dockerfile: docker/engine/Dockerfile
    command: processor --enable-metrics
    init: true
    volumes:
      - ./dev-environment/engine/dev-settings.toml:/user-settings.toml
      - ./src/os2datascanner:/code/src/os2datascanner
    depends_on:
      - queue

  matcher:
    build:
      context: .
      dockerfile: docker/engine/Dockerfile
    command: matcher --enable-metrics
    init: true
    restart: unless-stopped
    volumes:
      - ./dev-environment/engine/dev-settings.toml:/user-settings.toml
      - ./src/os2datascanner:/code/src/os2datascanner
    depends_on:
      - queue

  tagger:
    build:
      context: .
      dockerfile: docker/engine/Dockerfile
    command: tagger --enable-metrics
    init: true
    volumes:
      - ./dev-environment/engine/dev-settings.toml:/user-settings.toml
      - ./src/os2datascanner:/code/src/os2datascanner
    depends_on:
      - queue


volumes:
  frontend-bundles-admin:
  frontend-bundles-report:
  postgres-data:
  postgres-initdb.d:
  knr-postgres-keycloak-volume:
  ldap_data:
  ldap_config:
